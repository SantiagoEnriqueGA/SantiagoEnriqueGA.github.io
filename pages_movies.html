<!DOCTYPE HTML>
<html>
	<head>
		<title>Movie Spoiler Detector</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.27.0/themes/prism.min.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
		<div id="wrapper">

			<!-- Header -->
			<header id="header">
				<h1>Movie Spoiler Detector</h1>
				<p>A project to identify spoilers in user-generated movie reviews using machine learning.</p>
			</header>

			<!-- Main -->
			<div id="main">
				<!-- Content -->
				<section id="intro" class="main">
					<div class="spotlight">
						<div class="content">
							<header class="major">
								<h2>Project Overview</h2>
							</header>
							<p>This project focuses on detecting spoilers in user-generated movie reviews by applying machine learning models. Using a dataset from IMDB, the project involves preprocessing, feature engineering, model training, evaluation, and hyperparameter tuning.</p>

							<header class="major">
								<h2>Dataset</h2>
							</header>
							<ul>
								<li><strong>Total Records</strong>: 573,913</li>
								<li><strong>Users</strong>: 263,407</li>
								<li><strong>Movies</strong>: 1,572</li>
								<li><strong>Spoiler Reviews</strong>: 150,924</li>
								<li><strong>Users with at Least One Spoiler Review</strong>: 79,039</li>
								<li><strong>Items with at Least One Spoiler Review</strong>: 1,570</li>
							</ul>

                            <section id="model-selection">
                                <h2>Choices Faced When Selecting the Best Model</h2>
                                <ol>
                                    <li><strong>Balancing Precision and Recall</strong>:
                                        <ul>
                                            <li><strong>Precision</strong> measures how many selected items are relevant, while <strong>recall</strong> measures how many relevant items are selected.</li>
                                            <li>A model with high precision but low recall (e.g., <code>base_pytorch_lstm_best</code>) might be good for applications where false positives are costly.</li>
                                            <li>Conversely, a model with high recall but lower precision (e.g., <code>smote_k-nearest_neighbors</code>) might be suitable where missing a spoiler (false negative) is more detrimental.</li>
                                        </ul>
                                    </li>
                                    <li><strong>Considering Model Complexity and Training Time</strong>:
                                        <ul>
                                            <li>Neural networks like <code>base_pytorch_lstm_best</code> and <code>base_pytorch_ff_best</code> show good performance but at the cost of higher training and evaluation times.</li>
                                            <li>Models like <code>base_lightgbm_tuned</code> and <code>base_xgboost</code> offer a balance between performance and efficiency, making them attractive choices for practical deployment.</li>
                                        </ul>
                                    </li>
                                    <li><strong>Weighted Metrics</strong>:
                                        <ul>
                                            <li>Weighted metrics consider the support of each class, providing a more balanced view of the model's performance across all data points.</li>
                                            <li>For instance, <code>base_lightgbm_tuned</code> and <code>base_pytorch_lstm_best</code> score high on weighted average metrics, indicating robust overall performance.</li>
                                        </ul>
                                    </li>
                                    <li><strong>Hyperparameter Tuning</strong>:
                                        <ul>
                                            <li>Tuned models (<code>base_lightgbm_tuned</code>, <code>base_xgboost_tuned</code>) often perform better than their untuned counterparts.</li>
                                            <li>Investing time in hyperparameter optimization can yield significant performance gains.</li>
                                        </ul>
                                    </li>
                                    <li><strong>Evaluation Time</strong>:
                                        <ul>
                                            <li>For real-time or near-real-time applications, models with lower evaluation times (e.g., <code>base_linear_svc</code>, <code>base_logistic_regression</code>) might be preferred despite slightly lower accuracy or F1-scores.</li>
                                            <li><code>smote_logistic_regression</code> has the best evaluation time, which might be crucial for high-throughput systems.</li>
                                        </ul>
                                    </li>
                                    <li><strong>Use Case Specific Metrics</strong>:
                                        <ul>
                                            <li>Depending on the end-use case, certain metrics might be prioritized over others. For instance, if avoiding spoilers at any cost is critical, models with higher <code>1_recall</code> or <code>1_f1-score</code> would be prioritized, despite the increased probability of false positives.</li>
                                        </ul>
                                    </li>
                                </ol>
                    
                                <h3>Conclusion</h3>
                                <p>Selecting the best model for the Movie Spoiler Detector project involves balancing multiple performance metrics, considering model complexity, and evaluating practical constraints like training and evaluation times. The choice ultimately depends on the specific requirements of the deployment environment and the relative importance of precision, recall, and overall efficiency.</p>
                            </section>
                    
                            <section id="models">
                                <h2>Models</h2>
                    
                                <h3>Machine Learning Models</h3>
                                <table>
                                    <tr><th>Model</th><th>Description</th></tr>
                                    <tr><td><code>adaboost_model</code></td><td>Combines multiple weak classifiers to form a strong classifier by adjusting weights on errors.</td></tr>
                                    <tr><td><code>decision_tree_model</code></td><td>Splits data into subsets based on feature values, forming an intuitive, interpretable tree.</td></tr>
                                    <tr><td><code>gradient_boosting_model</code></td><td>Sequentially builds models to correct errors, optimizing for the loss function using gradient descent.</td></tr>
                                    <tr><td><code>k-nearest_neighbors_model</code></td><td>Classifies instances based on the majority class among nearest neighbors in feature space.</td></tr>
                                    <tr><td><code>lightgbm_model</code></td><td>Efficient gradient boosting framework for large datasets and high-dimensional data.</td></tr>
                                    <tr><td><code>linear_svc_model</code></td><td>Linear Support Vector Classifier effective in high-dimensional spaces, suitable for text classification.</td></tr>
                                    <tr><td><code>logistic_regression_model</code></td><td>Models binary outcomes using the logistic function, simple and interpretable.</td></tr>
                                    <tr><td><code>random_forest_model</code></td><td>Ensemble method building multiple decision trees, reducing overfitting and handling large datasets.</td></tr>
                                    <tr><td><code>sgd_classifier_model</code></td><td>Uses stochastic gradient descent to minimize loss, suitable for large-scale learning problems.</td></tr>
                                    <tr><td><code>xgboost_model</code></td><td>Optimized gradient boosting library, efficient and effective for structured/tabular data.</td></tr>
                                </table>
                            </section>

							<header class="major">
								<h2>Results</h2>
							</header>
							<h3>Top 10 Models by Accuracy</h3>
							<div class="table-wrapper">
								<table>
									<thead>
										<tr>
											<th>Model</th>
											<th>Accuracy</th>
											<th>0 Precision</th>
											<th>0 F1-score</th>
											<th>1 Precision</th>
											<th>1 F1-score</th>
											<th>Weighted Avg Precision</th>
											<th>Weighted Avg F1-score</th>
											<th>Eval Time</th>
										</tr>
									</thead>
									<tbody>
										<tr><td>base_pytorch_lstm_best</td><td>0.7934</td><td>0.8170</td><td>0.8683</td><td>0.6746</td><td>0.5205</td><td>0.7793</td><td>0.7762</td><td>25.18</td></tr>
										<tr><td>base_lightgbm_tuned</td><td>0.7928</td><td>0.8082</td><td>0.8699</td><td>0.7008</td><td>0.4922</td><td>0.7798</td><td>0.7699</td><td>0.44</td></tr>
										<tr><td>base_pytorch_ff_best</td><td>0.7906</td><td>0.8190</td><td>0.8657</td><td>0.6573</td><td>0.5245</td><td>0.7762</td><td>0.7754</td><td>19.90</td></tr>
										<tr><td>base_lightgbm</td><td>0.7884</td><td>0.8036</td><td>0.8675</td><td>0.6928</td><td>0.4740</td><td>0.7743</td><td>0.7634</td><td>0.11</td></tr>
										<tr><td>base_xgboost</td><td>0.7882</td><td>0.8060</td><td>0.8669</td><td>0.6830</td><td>0.4824</td><td>0.7734</td><td>0.7651</td><td>0.12</td></tr>
										<tr><td>smote_xgboost</td><td>0.7820</td><td>0.8050</td><td>0.8623</td><td>0.6537</td><td>0.4767</td><td>0.7649</td><td>0.7602</td><td>0.14</td></tr>
										<tr><td>base_linear_svc</td><td>0.7817</td><td>0.7988</td><td>0.8636</td><td>0.6719</td><td>0.4535</td><td>0.7652</td><td>0.7550</td><td>0.06</td></tr>
										<tr><td>base_logistic_regression</td><td>0.7815</td><td>0.8030</td><td>0.8625</td><td>0.6572</td><td>0.4696</td><td>0.7644</td><td>0.7585</td><td>0.06</td></tr>
										<tr><td>smote_lightgbm</td><td>0.7802</td><td>0.8072</td><td>0.8604</td><td>0.6395</td><td>0.4836</td><td>0.7628</td><td>0.7606</td><td>22.37</td></tr>
										<tr><td>base_gradient_boosting</td><td>0.7794</td><td>0.7894</td><td>0.8642</td><td>0.6986</td><td>0.4127</td><td>0.7654</td><td>0.7447</td><td>0.46</td></tr>
									</tbody>
								</table>
							</div>

							<h3>Best Models by Metric</h3>
							<div class="table-wrapper">
								<table>
									<thead>
										<tr><th>Metric</th><th>Best Performing Model</th></tr>
									</thead>
									<tbody>
										<tr><td>0_precision</td><td>smote_k-nearest_neighbors</td></tr>
										<tr><td>0_recall</td><td>base_random_forest</td></tr>
										<tr><td>0_f1-score</td><td>base_lightgbm_tuned</td></tr>
										<tr><td>0_support</td><td>base_adaboost...</td></tr>
									</tbody>
								</table>
							</div>

						</div>
					</div>
				</section>
			</div>

			<!-- Footer -->
			<footer id="footer">
				<section>
					<h2>Contact Me</h2>
					<dl class="alt">
						<dt>Phone</dt>
							<dd>(832) 296-3193</dd>
						<dt>Email</dt>
							<dd><a href="mailto:sega97@gmail.com">sega97@gmail.com</a></dd>
						<dt>LinkedIn</dt>
							<dd><a href="https://www.linkedin.com/in/santiago-e-gonzalez/">linkedin.com/in/santiago-e-gonzalez</a></dd>
						<dt>GitHub</dt>
							<dd><a href="https://github.com/SantiagoEnriqueGA/">github.com/SantiagoEnriqueGA</a></dd>
					</dl>
				</section>
				<p class="copyright">&copy; Untitled. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
			</footer>
		</div>

		<!-- Scripts -->
		<script>window.onload = function() {document.body.style.zoom = "75%";}</script>
		<script src="assets/js/jquery.min.js"></script>
		<script src="assets/js/jquery.scrollex.min.js"></script>
		<script src="assets/js/jquery.scrolly.min.js"></script>
		<script src="assets/js/browser.min.js"></script>
		<script src="assets/js/breakpoints.min.js"></script>
		<script src="assets/js/util.js"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.27.0/prism.min.js"></script>
		<script src="assets/js/main.js"></script>

	</body>
</html>
